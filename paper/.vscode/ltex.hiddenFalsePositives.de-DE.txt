{"rule":"F_ANSTATT_PH","sentence":"^\\QUm Daten über das Gehirn zu bekommen, nutzen wir einen Elektroenzephalographen, kurz EEG, welcher durch Elektroden an der Kopfhaut die Spannungsdifferenz innerhalb des Gehirns misst.\\E$"}
{"rule":"Z_ANSTATT_T","sentence":"^\\QDas Ziel ist es dann, durch das Erkennen verschiedener dieser sogenannten ereigniskorrelierten Potentiale (EKPs) einen Roboter nur mit Gedanken steuern zu können.\\E$"}
{"rule":"GERMAN_SPELLER_RULE","sentence":"^\\QDas Ziel ist es dann, durch das Erkennen verschiedener dieser sogenannten ereigniskorrelierten Potentiale (EKPs) einen Roboter nur mit Gedanken steuern zu können.\\E$"}
{"rule":"DE_CASE","sentence":"^\\Q\\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Wir hoffen, neben dem Erlangen von Erfahrung in diesem interessanten Bereich auch selbst dazu beizutragen.\\E$"}
{"rule":"DE_AGREEMENT","sentence":"^\\QDies wollen wir erreichen durch das Entwickeln einer allgemeinen Anwendung, bei der kein vorheriges Trainieren für eine fremde Person benötigt wird, das Umsetzen mit günstiger, für viele bezahlbarer Hardware, sowie ein performantes Programm, welches leicht für die eigenen Zwecke anpassbar ist.\\E$"}
{"rule":"GERMAN_SPELLER_RULE","sentence":"^\\QEEG 4 Channel Ganglion Board von OpenBCI \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q 2x Spike und 2x Flat Electrodes \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Klettband für die Elektroden \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q 2x Earclips \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Lithium-Polymer-Akku und Ladegerät \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Plastik-Hülle für das Ganglion Board\\E$"}
{"rule":"GERMAN_SPELLER_RULE","sentence":"^\\QEEG 4 Channel Ganglion Board von OpenBCI \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q 2x Spike und 2x Flat Electrodes \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Klettband für die Elektroden \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q 2x Earclips \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Lithium-Polymer-Akku und Ladegerät \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q Plastik-Hülle für das Ganglion Board\\E$"}
{"rule":"DE_CASE","sentence":"^\\QRoboter Lego Mindstorms EV3 Brick Raspberry Pi 3B 8 GB 2x EV3 großer Motor SD-Karte (8 GB) Diverse Legoteile\\E$"}
{"rule":"DE_CASE","sentence":"^\\QRoboter Lego Mindstorms EV3 Brick Raspberry Pi 3B 8 GB 2x EV3 großer Motor SD-Karte (8 GB) Diverse LEGO Teile\\E$"}
{"rule":"GERMAN_SPELLER_RULE","sentence":"^\\QSoftware Flux.jl für das neuronale Netz \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q BrainFlow.jl als Schnittstelle zum EEG \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q FFTW.jl für die Fast Fourier Transformation \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q CUDA.jl zum effektiven Nutzen einer NVIDIA GPU \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q PyPlot.jl zum Plotten \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q BSON.jl zum Speichern und Laden von Netzwerken ev3dev.jl zum Steuern eines EV3-Roboters durch einen Raspberry Pi \\E(?:Dummy|Ina|Jimmy-)[0-9]+$"}
{"rule":"GERMAN_SPELLER_RULE","sentence":"^\\QDie Neuronen verschiedener Layer sind alle durch sogenannte Gewichte (Weights) verbunden, die ebenfalls einen beliebigen Wert haben können.\\E$"}
{"rule":"UPPERCASE_SENTENCE_START","sentence":"^\\Qwobei \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q = die Cost des Output-Layers, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q = der letzte Layer (Output Layer), \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q = die Aktivierungen des Layers \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, und \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q = die richtigen Outputs für die Inputs, mit denen die Aktivierungen berechnet wurden.\\E$"}
{"rule":"GERMAN_SPELLER_RULE","sentence":"^\\QDiese Art der Cost-Funktion wird mittlere quadratische Abweichung (mean squared error, kurz MSE) genannt.\\E$"}
{"rule":"GERMAN_SPELLER_RULE","sentence":"^\\Qwobei \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q = um wie viel das Gewicht \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q zwischen den Neuronen \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q und \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q verändert werden muss, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q = die Lernrate (meist ein kleiner Wert wie 0.001), \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q die Ableitung der Cost des Neuronen \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q im Verhältnis zum Weight \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, und \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q = die Aktivierung des Neurons \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q.\\E$"}
{"rule":"UPPERCASE_SENTENCE_START","sentence":"^\\Qwobei \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q = um wie viel das Gewicht \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q zwischen den Neuronen \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q und \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q verändert werden muss, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q = die Lernrate (meist ein kleiner Wert wie 0.001), \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q die Ableitung der Cost des Neuronen \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q im Verhältnis zum Weight \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, und \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q = die Aktivierung des Neurons \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q.\\E$"}
{"rule":"UPPERCASE_SENTENCE_START","sentence":"^\\Qwobei \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q = um wie viel das Gewicht \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q zwischen den Neuronen \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q und \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q verändert werden muss, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q = die Lernrate (meist ein kleiner Wert wie 0.001), \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q die Ableitung der Cost des Neuronen \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q im Verhältnis zum Gewicht \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, und \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q = die Aktivierung des Neurons \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q.\\E$"}
{"rule":"UPPERCASE_SENTENCE_START","sentence":"^\\Qwobei \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q = die Ableitung von \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, also \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q = der Netzinput des Neurons \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q , \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q = die Aktivierung, die das Neuron haben sollte (also das gleiche wie \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q), und \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q = die Aktivierung, die das Neuron hat.\\E$"}
{"rule":"COMMA_IN_FRONT_RELATIVE_CLAUSE","sentence":"^\\QFür die Neuronen der Hidden Layers muss man alle \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q's des nächsten Layers mit den von dem Neuron dorthin führenden Gewicht multiplizieren und dann summieren.\\E$"}
{"rule":"UPPERCASE_SENTENCE_START","sentence":"^\\Qwobei \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q = der nächste Layer, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q = alle \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q's des Layers \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, und \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q = alle Gewichte, die ein Neuron des nächsten Layers und Neuron \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q verbinden.\\E$"}
{"rule":"GERMAN_SPELLER_RULE","sentence":"^\\QFür dieses Projekt haben wir allerdings das Package Flux benutzt, welches die gleichen Ergebnisse liefern sollte, jedoch mit deutlich besserer Performance, da es sehr stark optimiert wurde.\\E$"}
{"rule":"GERMAN_SPELLER_RULE","sentence":"^\\QWir haben dafür das Package ev3dev.jl benutzt, welches wir bereits für die Robotik-AG programmiert hatten.\\E$"}
{"rule":"GERMAN_SPELLER_RULE","sentence":"^\\QMehr technische Details zu der Umsetzung lassen sich beim GitHub Repository des Packages finden \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q.\\E$"}
{"rule":"GERMAN_SPELLER_RULE","sentence":"^\\QDabei beginnt man im ersten Hidden Layer damit, für alle Neuronen den sogenannten Netzinput (auch net input) zu berechnen.\\E$"}
{"rule":"UPPERCASE_SENTENCE_START","sentence":"^\\Qwobei \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q = die Ableitung von \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, also \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q = der Netzinput des Neurons \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q, \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q = die Aktivierung, die das Neuron haben sollte (also das gleiche wie \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q), und \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q = die Aktivierung, die das Neuron hat.\\E$"}
{"rule":"EINHEIT_LEERZEICHEN","sentence":"^\\QUnser Netzwerk haben wir aber nur mit 90% dieser Datensätze (180) trainiert, damit wir mit den restlichen 20 kontrollieren konnten, ob das Netzwerk auch unbekannte Daten richtig verarbeiten kann.\\E$"}
{"rule":"GERMAN_SPELLER_RULE","sentence":"^\\QDer Cost- und Genauigkeitsverlauf der Test- und Trainingsdaten beim Trainieren des Netwerkes ohne FFT\\E$"}
{"rule":"EINHEIT_LEERZEICHEN","sentence":"^\\QWie man an Abbildung \\E(?:Dummy|Ina|Jimmy-)[0-9]+\\Q sehen kann, erreichte das neuronale Netzwerk in diesem Fall in nur 1000 Epochen (ca. 5 Minuten Rechenzeit) eine Genauigkeit von 95%, bei anderen Durchläufen erhielten wir auch 100%.\\E$"}
{"rule":"GERMAN_SPELLER_RULE","sentence":"^\\QDer Cost- und Genauigkeitsverlauf der Test- und Trainingsdaten beim Trainieren des Netwerkes mit FFT\\E$"}
{"rule":"EINHEIT_LEERZEICHEN","sentence":"^\\QDie Kosten der benutzten Hardware halten sich jedoch noch in Grenzen: Beim Kauf hat die gesamte EEG-Ausstattung ca. 550€ gekostet.\\E$"}
{"rule":"GERMAN_SPELLER_RULE","sentence":"^\\QDanke an Professor Everling vom The Brain and Mind Institute der Western University in Kanada, der uns geholfen hat, einen Ansatz in diesem komplizierten Thema zu finden.\\E$"}
{"rule":"GERMAN_SPELLER_RULE","sentence":"^\\QDanke an Ino Saathoff, der für uns die Hülle der EEG-Platine mit seinem 3D-Drucker erstellt hat.\\E$"}
{"rule":"GERMAN_WORD_REPEAT_BEGINNING_RULE","sentence":"^\\QDanke an Oliver Samkovskij und Ino, die zusammen mit uns den Roboter gebaut haben.\\E$"}
{"rule":"GERMAN_SPELLER_RULE","sentence":"^\\QDanke an Oliver Samkovskij und Ino, die zusammen mit uns den Roboter gebaut haben.\\E$"}
